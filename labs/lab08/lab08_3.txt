Exercise 3:

  A:
    The FTRL optimizer must under the hood dynamically change the learning rate. The code we see meerly sets the starting learning rate.

  B:
    Binning is useful for eliminating noise or non-linearity in the data. Some features may not have a fully linear relationship with the target or they may be some error in the values. Grouping them into buckets and one-hot encoding them minimizes the error that may be reported. Additionally, instead of the model trying to find a linear relationship that may not exist, it instead can focus on the relationship betweent he proximity of values. For example, increasing lattitude may not tell us anything useful. However, lattitudes in certain ranges may be more effective.

  C:

    Task 1 (only the code I modified):

      bucketized_latitude = tf.feature_column.bucketized_column(
    longitude, boundaries=get_quantile_based_boundaries(
      training_examples["latitude"], 10))

    bucketized_housing_median_age = tf.feature_column.bucketized_column(
      longitude, boundaries=get_quantile_based_boundaries(
        training_examples["longitude"], 7))

    bucketized_median_income =tf.feature_column.bucketized_column(
      households, boundaries=get_quantile_based_boundaries(
        training_examples["median_income"], 7))

    bucketized_rooms_per_person = tf.feature_column.bucketized_column(
      households, boundaries=get_quantile_based_boundaries(
        training_examples["rooms_per_person"], 7))

    This code makes sense. The given get_quantile_based_boundaries function makes the code more readbale and bucketized_column function is intuitive.

    Task 2:

        long_x_lat = tf.feature_column.crossed_column(
    [bucketized_longitude, bucketized_latitude], 1000, hash_key=None
      )

      Crossing total_rooms and total_households might be a useful feature cross.