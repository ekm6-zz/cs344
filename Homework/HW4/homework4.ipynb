{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4_ekm6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBBXGCXXOSMu",
        "colab_type": "text"
      },
      "source": [
        "# Homework #4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2yOOHWaOYwL",
        "colab_type": "text"
      },
      "source": [
        "Enoch Mwesigwa <br/>\n",
        "Keith Vander Linden <br/>\n",
        "CS 344\n",
        "April 24th, 2020\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lakqu3e5OIHq",
        "colab_type": "text"
      },
      "source": [
        "## Question 1:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQzZPyusOOO6",
        "colab_type": "text"
      },
      "source": [
        "Attempting to answer such a question is deeply speculative. It is heavily dependent on the new technologies as well as challenges that arise. Something is only a “bust” if it encounters a challenge that renders it useless or a better alternative presents itself. To date, deep learning is the most effective machine learning tool we have. It doesn’t have the shortcomings of it’s predecessors. Unlike expert systems, it doesn’t require extensive knowledge of the subject matter, it merely requires the adequate data. Unlike perceptrons, “deep” neural networks are able to learn “non-linear” solutions. \n",
        "\n",
        "However, “deep” neural networks don’t come without their drawbacks. They can be computationally expensive. These have both financial and environmental ramifications. This is a serious problem since the rate at which machine computation power seems to be plateauing. Modern deep learning methods seem to demand more and more compomputation power (ie google GPU farms). Without some major breakthroughs in computer chip technology, the rate of progress may begin to slow.\n",
        "\n",
        "Despite these challenges, deep learning is at the forefront of innovation. Whether automotives, financic, and even law, deep learning has touched nearly every industry. And it will continue to do so until a vastly better alternative presents itself. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjdnGHSVOsBp",
        "colab_type": "text"
      },
      "source": [
        "## Question 2:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-1dRHTnOzIX",
        "colab_type": "text"
      },
      "source": [
        "1. Fill in weights from class\n",
        "\n",
        "![alt text](https://render.githubusercontent.com/render/math?math=%5Cbegin%7Baligned%7D%0A%20%26amp%3B%5Cbegin%7Bbmatrix%7D%0A%20w_%7Bi_1%2Ch_1%7D%20%26amp%3B%20w_%7Bi_1%2Ch_2%7D%20%5C%5C%0A%20w_%7Bi_2%2Ch_1%7D%20%26amp%3B%20w_%7Bi_2%2Ch_2%7D%0A%20%5Cend%7Bbmatrix%7D%0A%20%5Cleftarrow%0A%20%5Cbegin%7Bbmatrix%7D%0A%200.11%20%26amp%3B%200.12%20%5C%5C%0A%200.21%20%26amp%3B%200.08%0A%20%5Cend%7Bbmatrix%7D%20%5C%5C%0A%20%26amp%3B%5Cbegin%7Bbmatrix%7D%0A%20w_%7Bh_1%2C%20o_1%7D%20%5C%5C%20%0A%20w_%7Bh_2%2C%20o_1%7D%20%0A%20%5Cend%7Bbmatrix%7D%0A%20%5Cleftarrow%0A%20%5Cbegin%7Bbmatrix%7D%0A%200.14%20%5C%5C%0A%200.15%0A%20%5Cend%7Bbmatrix%7D%0A%20%5Cend%7Baligned%7D&mode=inline)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WXXfvPDQtjZ",
        "colab_type": "text"
      },
      "source": [
        "2. Compute the output for one sample (XOR: [1, 1] → 0)<br/>\n",
        "\n",
        "$o_j$ = $\\begin{bmatrix}1 & 1\\end{bmatrix}$ $\\cdot$ $\\begin{bmatrix}.11 & .12 \\\\ .21 & .08\\end{bmatrix}$ $\\cdot$ $\\begin{bmatrix}.14 & .15\\end{bmatrix}$ <br/>\n",
        "$o_j$ = $\\begin{bmatrix}.32 & .2\\end{bmatrix}$ $\\cdot$ $\\begin{bmatrix}.14 \\\\ .15\\end{bmatrix}$\n",
        "\n",
        "$o_j$ = .0748\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLvzXlftWIYJ",
        "colab_type": "text"
      },
      "source": [
        "3. Compute the error<br/>\n",
        "$L_2$Error = $(0-.0748)^2$<br/>\n",
        "= .00559504 <br/>\n",
        "$\\Delta_{o1}$ = 0-.0748 = .0748\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGJctRC6YCPk",
        "colab_type": "text"
      },
      "source": [
        "4. Back-propagate updates back through the network, assuming:  $learning\\_rate = 0.05$; f(x) = x activation functions for all nodes. <br/>\n",
        "\n",
        "$\\begin{bmatrix} W_{h1}, o_1 \\\\ W_{h_2}, o_1\\end{bmatrix}$ $\\leftarrow$ $\\begin{bmatrix}.14 \\\\ .15\\end{bmatrix}$ + .05 $\\cdot$ $\\begin{bmatrix}.32 & .2\\end{bmatrix}$ $\\cdot$ 1 $\\cdot$ .0748 <br/>\n",
        "\n",
        "$\\begin{bmatrix} W_{h_1}, o_1 \\\\ W_{h_2}, o_1\\end{bmatrix}$ $\\leftarrow$ $\\begin{bmatrix}.14 \\\\ .15\\end{bmatrix}$ $\\cdot$ $\\begin{bmatrix} -.0011968 \\\\ -.00748\\end{bmatrix}$ <br/>\n",
        "\n",
        "$\\begin{bmatrix} W_{h_1}, o_1 \\\\ W_{h_2}, o_1\\end{bmatrix}$ $\\leftarrow$ $\\begin{bmatrix}.1388032 \\\\ .149252\\end{bmatrix}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac8syNNQdxuf",
        "colab_type": "text"
      },
      "source": [
        "$\\begin{bmatrix} W_{i_1}, h_1 & W_{i_1}, h_2\\\\ W_{i_2}, h_1 & W_{i_2}, h_2 \\end{bmatrix}$ $\\leftarrow$ $\\begin{bmatrix}.11 & .12 \\\\ .21 & .08\\end{bmatrix}$ + .05 + $\\begin{bmatrix}1 & 1 \\\\ 1 & 1\\end{bmatrix}$ $\\bigodot$ $\\begin{bmatrix}.14 & .15 \\\\ .14 & .15\\end{bmatrix}$ -.0748 <br/>\n",
        "\n",
        "$\\begin{bmatrix} W_{i_1}, h_1 & W_{i_1}, h_2\\\\ W_{i_2}, h_1 & W_{i_2}, h_2 \\end{bmatrix}$ $\\leftarrow$ $\\begin{bmatrix}.1094764 & .119439 \\\\ .2094764 & .079439\\end{bmatrix}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aduWFQJBhWYh",
        "colab_type": "text"
      },
      "source": [
        "## Question 3:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTjgui2whabx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras.optimizers import RMSprop, Adagrad, Adam\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbyRXX5CiM_L",
        "colab_type": "code",
        "outputId": "2ccb7b1a-d5b5-4303-d829-93e3d08b0f7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIpsJtM8j09m",
        "colab_type": "code",
        "outputId": "981133ae-2c65-4498-c248-94376e7f0188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "# Configure a convnet with 3 layers of convolutions and max pooling.\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "#flatten\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "#set up 10-way classification\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_25 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 1, 1, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 97,482\n",
            "Trainable params: 97,482\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1I-2PS-j1UH",
        "colab_type": "code",
        "outputId": "81d522ce-1d1c-4470-dd01-088343f28a69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "model.compile(Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=64)\n",
        "print(\"accuracy\", model.evaluate(test_images, test_labels)[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 50s 830us/step - loss: 0.2068 - accuracy: 0.9352\n",
            "Epoch 2/10\n",
            "51456/60000 [========================>.....] - ETA: 7s - loss: 0.0565 - accuracy: 0.9829"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}