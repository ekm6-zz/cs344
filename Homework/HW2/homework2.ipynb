{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2\n",
    "Enoch Mwesigwa\n",
    "Keith Vanderlinden\n",
    "CS 344\n",
    "March 17th, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " The message ['do', 'i', 'like', 'green', 'eggs'] has a  6.407996462188124e-06 chance of being spam\n",
      "\n",
      "\n",
      " The message ['I', 'do', 'not', 'like', 'spam'] has a  0.9972779006872371 chance of being spam\n",
      "\n",
      "\n",
      " The message ['I', 'am', 'green', 'eggs', 'like', 'spam'] has a  0.25471134298672354 chance of being spam\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "spam_corpus = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"that\", \"spamiam\"]]\n",
    "ham_corpus = [[\"do\", \"i\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"], [\"i\", \"do\"]]\n",
    "\n",
    "class SpamFilter:\n",
    "    def __init__(self,bad_words, good_words):\n",
    "        #lowercase and flatten lists + get counts of words\n",
    "        self.good_words = Counter( [ word.lower() for word in np.concatenate(good_words)] )\n",
    "        self.bad_words = Counter( [ word.lower() for word in np.concatenate(bad_words)] )\n",
    "        self.construct_prob_table()\n",
    "        \n",
    "    # calculates probabilities without as specified by article   \n",
    "    def calc_probs(self, word):\n",
    "        g = 2 * self.in_dict(self.good_words, word, .01 )\n",
    "        b = self.in_dict(self.bad_words, word, .01)\n",
    "        if (g + b) > 1:\n",
    "                return ( max(0.01, min(0.99, min(1.0, b / len(self.bad_words)) / \n",
    "                                 (min(1.0, g / len(self.good_words)) + min(1.0, b / len(self.bad_words)))))\n",
    "                       )\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    #constructs a probability table from the words\n",
    "    def construct_prob_table(self):\n",
    "        self.prob_table = dict(map(\n",
    "        lambda word: (word, self.calc_probs(word)), self.good_words + self.bad_words\n",
    "    ))\n",
    "    \n",
    "    #returns value of if targe exits in dict\n",
    "    # else returns false value\n",
    "    def in_dict(self, obj, target, default):\n",
    "        if target in obj:\n",
    "            return obj[target] \n",
    "        else:\n",
    "            return default\n",
    "\n",
    "    #returns the probability of a given word being spam\n",
    "    def get_prob(self, word):\n",
    "        return self.in_dict(self.prob_table, word, .5)\n",
    "    \n",
    "    def is_spam(self, message):\n",
    "        probs = list(map(self.get_prob, message))\n",
    "        product = np.prod(probs)\n",
    "        product_complement = (product + np.prod( list(map(lambda element: 1 - element, probs)) ))\n",
    "        return product / product_complement\n",
    "    \n",
    "    # calculates and displays the likelihood of multiple messages being spam\n",
    "    def calc_spam(self, message_list):\n",
    "        for message in message_list:\n",
    "            print(\"\\n\\n The message\", message, \"has a \", self.is_spam(message), \"chance of being spam\")\n",
    "        \n",
    "spf = SpamFilter(spam_corpus, ham_corpus)\n",
    "test_list = [\"do i like green eggs\".split(), \"I do not like spam\".split(), \"I am green eggs like spam\".split()]\n",
    "\n",
    "spf.calc_spam(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach is Baysian because it uses the Bayes Rule in the sense that we calculate the probability of the cause when we're given it's effect. In this case, the email is the effect. We use it to calculate the probability of whether it is or isn't spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from probability import BayesNet, enumeration_ask, elimination_ask, gibbs_ask\n",
    "\n",
    "T, F = True, False\n",
    "\n",
    "weather = BayesNet([\n",
    "    ('Cloudy', '', 0.5),\n",
    "    ('Sprinkler', 'Cloudy', {T: 0.1, F: 0.5}),\n",
    "    ('Rain', 'Cloudy', {T: 0.8, F: 0.2}),\n",
    "    ('WetGrass', 'Sprinkler Rain', {(T, T): 0.99, (T, F): 0.9, (F, T): 0.9, (F, F): 0})\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of random variables = 4\n",
    "<br/>\n",
    "number of options for each = 2\n",
    "<br/>\n",
    "work: <br/>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2^4 = 16 <br/>\n",
    "solution:<br/>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   There are 16 independent values in the full joint probability distribution for this domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 9 independent values total in the Bayesian network:\n",
    "* Cloudy: 1 independent value\n",
    "* Sprinkler: 2 values\n",
    "* Rain: 2 values\n",
    "* Wetgrass: 2 values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i.\n",
      "False: 0.5, True: 0.5\n",
      "\n",
      "ii.\n",
      "False: 0.9, True: 0.1\n",
      "\n",
      "iii.\n",
      "False: 0.952, True: 0.0476\n",
      "\n",
      "iv.\n",
      "False: 0.01, True: 0.99\n",
      "\n",
      "v.\n",
      "False: 0.639, True: 0.361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"i.\")\n",
    "print(enumeration_ask('Cloudy', dict(), weather).show_approx())\n",
    "'''\n",
    "    P(Cloudy) = alpha * <P(Cloudy), P(~Cloudy)>\n",
    "\n",
    "    P(Cloudy) = alpha * <0.5, 0.5>\n",
    "\n",
    "    P(Cloudy) = <0.5, 0.5>\n",
    "\n",
    "'''\n",
    "print()\n",
    "print(\"ii.\")\n",
    "print(enumeration_ask('Sprinkler', dict(Cloudy=T), weather).show_approx())\n",
    "\n",
    "'''\n",
    "P(Sprinkler | Cloudy) = alpha * <0.1, 0.9>\n",
    "\n",
    "P(Sprinkler | Cloudy) = <0.1, 0.9>\n",
    "'''\n",
    "\n",
    "print()\n",
    "print(\"iii.\")\n",
    "print(enumeration_ask('Cloudy', dict(Sprinkler=T, Rain=F), weather).show_approx())\n",
    "\n",
    "'''\n",
    "P(Cloudy | Sprinkler ^ ~Rain) = \n",
    "    alpha * [ <P(Cloudy) * P(Sprinkler | Cloudy) * P(~Rain | Cloudy),\n",
    "    P(~Cloudy) * P(Sprinkler | ~Cloudy) * P(~Rain | ~Cloudy)> ]\n",
    "\n",
    "P(Cloudy | Sprinkler ^ ~Rain) = alpha * <0.5 * 0.1 * 0.2, 0.5 * 0.5 * 0.8>\n",
    "\n",
    "P(Cloudy | Sprinkler ^ ~Rain) = <0.952, 0.0476>\n",
    "'''\n",
    "\n",
    "print()\n",
    "print(\"iv.\")\n",
    "print(enumeration_ask('WetGrass', dict(Cloudy=T, Sprinkler=T, Rain=T), weather).show_approx())\n",
    "\n",
    "'''\n",
    "    P(WetGrass | Cloudy ^ Sprinkler ^ Rain) = \n",
    "    alpha * [ <P(WetGrass | Sprinkler ^ Rain) * P(Sprinkler | Cloudy) * P(Rain | Cloudy) * P(Cloudy),\n",
    "    P(~WetGrass | Sprinkler ^ Rain) * P(Sprinkler | Cloudy) * P(Rain | Cloudy) * P(Cloudy)> ]\n",
    "\n",
    "    P(WetGrass | Cloudy ^ Sprinkler ^ Rain) = alpha * <0.99 * 0.1 * 0.8 * 0.5, 0.01 * 0.1 * 0.8 * 0.5>\n",
    "\n",
    "    P(WetGrass | Cloudy ^ Sprinkler ^ Rain) = <0.99, 0.01>\n",
    "'''\n",
    "\n",
    "print()\n",
    "print(\"v.\")\n",
    "print(enumeration_ask('Cloudy', dict(WetGrass=F), weather).show_approx())\n",
    "\n",
    "'''\n",
    "\n",
    "P(Cloudy | ~WetGrass) = \n",
    "    alpha * [\n",
    "    P(Cloudy, ~WetGrass, Sprinkler, Rain) +\n",
    "    P(Cloudy, ~WetGrass, Sprinkler, ~Rain) +\n",
    "    P(Cloudy, ~WetGrass, ~Sprinkler, ~Rain) +\n",
    "    P(Cloudy, ~WetGrass, ~Sprinkler, Rain)\n",
    "    ]\n",
    "\n",
    "P(Cloudy, ~WetGrass, Sprinkler, Rain) = <0.5 * 0.1 * 0.8 * 0.01, 0.5 * 0.5 * 0.2 * 0.01>\n",
    "\n",
    "P(Cloudy, ~WetGrass, Sprinkler, ~Rain) = <0.5 * 0.1 * 0.2 * 0.1, 0.5 * 0.5 * 0.8 * 0.1>\n",
    "\n",
    "P(Cloudy, ~WetGrass, ~Sprinkler, ~Rain) = <0.5 * 0.9 * 0.2 * 1, 0.5 * 0.5 * 0.8 1>\n",
    "\n",
    "P(Cloudy, ~WetGrass, ~Sprinkler, Rain) = <0.5 * 0.9 * 0.8 * 0.1, 0.5 * 0.5 * 0.2 * 0.1>\n",
    "\n",
    "P(Cloudy | ~WetGrass) = alpha * <0.1274, 0.2255>\n",
    "\n",
    "P(Cloudy | ~WetGrass) = <0.361, 0.639>\n",
    "\n",
    "'''\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
